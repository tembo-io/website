"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[8501],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>h});var n=a(67294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var i=n.createContext({}),u=function(e){var t=n.useContext(i),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},c=function(e){var t=u(e.components);return n.createElement(i.Provider,{value:t},e.children)},m="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},p=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,r=e.originalType,i=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),m=u(a),p=o,h=m["".concat(i,".").concat(p)]||m[p]||d[p]||r;return a?n.createElement(h,s(s({ref:t},c),{},{components:a})):n.createElement(h,s({ref:t},c))}));function h(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=a.length,s=new Array(r);s[0]=p;var l={};for(var i in t)hasOwnProperty.call(t,i)&&(l[i]=t[i]);l.originalType=e,l[m]="string"==typeof e?e:o,s[1]=l;for(var u=2;u<r;u++)s[u]=a[u];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}p.displayName="MDXCreateElement"},88121:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>i,contentTitle:()=>s,default:()=>d,frontMatter:()=>r,metadata:()=>l,toc:()=>u});var n=a(87462),o=(a(67294),a(3905));const r={slug:"optimizing-postgres-auto-vacuum",title:"Optimizing Postgres's Autovacuum for High-Churn Tables",authors:["adam"],tags:["postgres"]},s=void 0,l={permalink:"/blog/optimizing-postgres-auto-vacuum",editUrl:"https://github.com/tembo-io/website/blob/main/blog/2023-08-31-tuning-autovacuum/index.md",source:"@site/blog/2023-08-31-tuning-autovacuum/index.md",title:"Optimizing Postgres's Autovacuum for High-Churn Tables",description:"Database systems use various techniques to ensure transactionality and performance. For Postgres, this is called MVCC (Multi-Version Concurrency Control). MVCC allows Postgres to provide great performance even when multiple clients could be working with the same table concurrently.",date:"2023-08-31T00:00:00.000Z",formattedDate:"August 31, 2023",tags:[{label:"postgres",permalink:"/blog/tags/postgres"}],readingTime:9.64,hasTruncateMarker:!1,authors:[{name:"Adam Hendel",title:"Founding Engineer",url:"https://github.com/ChuckHend",email:"noreply@tembo.io",imageURL:"https://github.com/chuckhend.png",key:"adam"}],frontMatter:{slug:"optimizing-postgres-auto-vacuum",title:"Optimizing Postgres's Autovacuum for High-Churn Tables",authors:["adam"],tags:["postgres"]},prevItem:{title:"Tembo Stacks: Making Postgres the Everything Database",permalink:"/blog/tembo-stacks-intro"},nextItem:{title:"Using pgmq with Python",permalink:"/blog/pgmq-with-python"}},i={authorsImageUrls:[void 0]},u=[{value:"Why does it matter?",id:"why-does-it-matter",level:2},{value:"Unraveling the Mystery of Bloat &amp; Vacuum&#39;s Role",id:"unraveling-the-mystery-of-bloat--vacuums-role",level:2},{value:"Setting up a benchmarking environment",id:"setting-up-a-benchmarking-environment",level:2},{value:"Balancing Vacuum Delay for Optimal System Performance",id:"balancing-vacuum-delay-for-optimal-system-performance",level:2},{value:"Fine-Tuning Auto Vacuum Scale Factors",id:"fine-tuning-auto-vacuum-scale-factors",level:2},{value:"A Quick Siesta for Your System",id:"a-quick-siesta-for-your-system",level:2},{value:"More on this topic",id:"more-on-this-topic",level:2}],c={toc:u},m="wrapper";function d(e){let{components:t,...r}=e;return(0,o.kt)(m,(0,n.Z)({},c,r,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,"Database systems use various techniques to ensure transactionality and performance. For Postgres, this is called MVCC (Multi-Version Concurrency Control). MVCC allows Postgres to provide great performance even when multiple clients could be working with the same table concurrently."),(0,o.kt)("p",null,"It is useful to be aware of Postgres\u2019 MVCC implementation to understand how Postgres manages a table\u2019s physical storage. Internally, Postgres refers to rows as \u201ctuples\u201d. And as a baseline, there are two big ideas to keep in mind about how Postgres implements changes to rows in a table:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},"An UPDATE operation in Postgres is equivalent to a DELETE of the previous tuple, plus an INSERT of the new one."),(0,o.kt)("li",{parentName:"ul"},"A DELETE operation in Postgres does not cause the data to be removed from physical storage. It only causes it to be marked as deleted.")),(0,o.kt)("p",null,"This is why Postgres has the ",(0,o.kt)("a",{parentName:"p",href:"https://www.postgresql.org/docs/current/routine-vacuuming.html#AUTOVACUUM"},"autovacuum")," process: It is the automatic process in charge of cleaning up and optimizing table storage for Postgres. You can follow this blog post with a local test environment of Postgres. I will demonstrate with code how MVCC and VACUUM features work, and how to tune the Auto-vacuum process."),(0,o.kt)("h2",{id:"why-does-it-matter"},"Why does it matter?"),(0,o.kt)("p",null,"Vacuum is not just about cleaning up storage space. In environments where data undergoes constant change, Postgres tables often experience an excessive amount of Inserts, Updates, and Deletes. This activity can lead to table bloat. Table bloat happens when a table\u2019s physical footprint far exceeds the size of the data that it actually holds."),(0,o.kt)("p",null,"Table bloat is a condition that if not managed, will likely hamper performance of our database. And so, this takes us back to the autovacuum process: to extract its maximum benefits, you may need to fine-tune its settings."),(0,o.kt)("p",null,"Postgres\u2019s default autovacuum settings are pretty good. If you\u2019re like me, it could have been years into your postgres journey before having a negative experience with bloat. However, when the time came I found it challenging to understand and tune these configuration settings. That\u2019s why we will study them safely in a dev environment."),(0,o.kt)("h2",{id:"unraveling-the-mystery-of-bloat--vacuums-role"},"Unraveling the Mystery of Bloat & Vacuum's Role"),(0,o.kt)("p",null,'PostgreSQL\'s mechanism for handling bloat is unique due to its adherence to MVCC. Contrary to immediate space reclamation after data is deleted or becomes obsolete, Postgres tags these rows as "dead", or \u201cdead tuples\u201d. However, even though they are dead they still occupy disk space and will degrade the performance of your queries. Many queries will continue to scan through these tuples, despite their \u201cdead\u201d status. The auto-vacuum steps in here, ensuring that these rows are removed and both the table and its associated indexes are streamlined for performance. You can\u2019t scan the dead tuples if they no longer exist!'),(0,o.kt)("p",null,"To illustrate, let us create some bloat and see how it affects a rowcount query:"),(0,o.kt)("p",null,"Create a table we can easily manipulate, and let\u2019s disable autovacuum so we can observe the consequences."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE TABLE bencher (\n  record_id bigserial,\n  updated_at timestamp with time zone\n);\nALTER TABLE bencher SET (autovacuum_enabled = false);\nSELECT pg_reload_conf();\n")),(0,o.kt)("p",null,"Now insert 10 million rows of example data."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO bencher(updated_at)\nSELECT now()\nFROM generate_series(1, 10000000);\n")),(0,o.kt)("p",null,"We just created the table, and have only inserted records, so there are currently no dead tuples."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT\n    schemaname,\n    relname,\n    n_dead_tup,\n    n_live_tup\nFROM pg_stat_user_tables\nWHERE relname = 'bencher';\n\n schemaname | relname | n_dead_tup | n_live_tup \n------------+---------+------------+------------\n public     | bencher |          0 |   10000000\n\n")),(0,o.kt)("p",null,"Let\u2019s see how long it takes to get a rowcount with no bloat."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"\\timing\n\nselect * from bencher where record_id = 5000000;\nrecord_id | updated_at\n-----------+-------------------------------\n5000000 | 2023-08-30 14:42:05.584778+00\n(1 row)\n\nTime: 191.006 ms\n")),(0,o.kt)("p",null,"Great, 191ms. Slow, yes but we have no indices because we\u2019re demonstrating bloat. Now lets create a bunch of dead tuples. This can take a minute or so."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"DO $$\nDECLARE\ni integer;\nBEGIN\nFOR i IN 1..5 LOOP\n  UPDATE bencher SET updated_at = now();\nEND LOOP;\nEND $$;\n")),(0,o.kt)("p",null,"Now, lets see how long it takes to fetch the same record:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"select * from bencher where record_id = 5000000;\nrecord_id | updated_at\n-----------+-------------------------------\n5000000 | 2023-08-30 14:42:58.964919+00\n(1 row)\n\nTime: 283.728 ms\n")),(0,o.kt)("p",null,"It\u2019s getting closer to 300ms now. Let\u2019s check how many dead tuples are on the table."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT\n    schemaname,\n    relname,\n    n_dead_tup,\n    n_live_tup\nFROM pg_stat_user_tables\nWHERE relname = 'bencher';\n\n\nschemaname | relname | n_dead_tup | n_live_tup\n------------+---------+------------+------------\npublic | bencher | 50000000 | 10000000\n")),(0,o.kt)("p",null,"Now let\u2019s manually clean up the dead tuples and restore our query performance."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"VACUUM FULL bencher;\n")),(0,o.kt)("p",null,"And check the dead tuple count, there are no dead tuples."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT\n    schemaname,\n    relname,\n    n_dead_tup,\n    n_live_tup\nFROM pg_stat_user_tables\nWHERE\n    n_dead_tup > 0 --needed to avoid division by zero\nand relname = 'bencher';\n schemaname | relname | n_dead_tup | n_live_tup \n------------+---------+------------+------------\n public     | bencher |          0 |    10000000\n")),(0,o.kt)("p",null,"Finally, let\u2019s retrieve the record. Performance restored!"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"select * from bencher where record_id = 500000;\nrecord_id | updated_at\n-----------+-------------------------------\n500000 | 2023-08-30 14:42:58.964919+00\n(1 row)\n\nTime: 194.101 ms\n")),(0,o.kt)("h2",{id:"setting-up-a-benchmarking-environment"},"Setting up a benchmarking environment"),(0,o.kt)("p",null,"The rest of the examples will be run on Postgres in ",(0,o.kt)("a",{parentName:"p",href:"https://cloud.tembo.io"},"Tembo Cloud"),". We\u2019ll use 8 vcore and 16Gb of memory and execute all the ",(0,o.kt)("inlineCode",{parentName:"p"},"psql")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"pgbench")," commands from an EC2 instance within the same region as Postgres."),(0,o.kt)("p",null,"Let\u2019s set up a script that will create an absurdly large amount of churn on our table and be able to execute it with ",(0,o.kt)("inlineCode",{parentName:"p"},"pgbench"),". For every iteration, let\u2019s insert a row to our \u201cbencher\u201d table. Then, let\u2019s read and update a single record. Finally, let\u2019s delete the same record. This will create a situation similar to many queue implementations (",(0,o.kt)("a",{parentName:"p",href:"https://github.com/tembo-io/pgmq"},"like PGMQ"),"), where there are at least 2 transactions for every 1 insert. Additionally, the total record count on the table will typically be low - for every record we insert, we also delete one."),(0,o.kt)("p",null,"This creates a situation where a table consists of primarily dead tuples!"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"-\u2013 churn.sql\nDO $$\nDECLARE\nrec_id INT;\nBEGIN\n    INSERT INTO bencher(updated_at)\nSELECT now();\n\n-- read and update a row\nWITH cte AS\n(\n    SELECT record_id\n    FROM bencher\n    WHERE updated_at < now()\n    ORDER BY record_id ASC\n    LIMIT 1\nFOR UPDATE SKIP LOCKED\n)\n\n\nUPDATE bencher\nSET\n    updated_at = now()\nWHERE record_id in (select record_id from cte)\nRETURNING record_id INTO rec_id;\n\n\n-- Delete the row with the returned ID\nDELETE\nFROM bencher\nWHERE record_id = rec_id;\nEND $$;\n")),(0,o.kt)("p",null,"Set Postgres to all the default vacuum configurations;"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER SYSTEM SET autovacuum_vacuum_scale_factor = 0.2;\nALTER SYSTEM SET autovacuum_vacuum_cost_delay = '20ms';\nALTER SYSTEM SET autovacuum_vacuum_cost_limit = '-1';\nALTER SYSTEM SET vacuum_cost_limit = 200;\nALTER SYSTEM SET autovacuum_naptime = '1min';\nSELECT pg_reload_conf();\n")),(0,o.kt)("p",null,"Let\u2019s run a benchmark to get a baseline. We will reuse this benchmark through the process."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sh"},"pgbench 'postgresql://postgres:pw@host:5432' -c 100 -j 1 -P 1 -T 300 -r -f churn.sql\n")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"default",src:a(73393).Z,title:"default",width:"1000",height:"600"})),(0,o.kt)("p",null,"Average latency is about 3.4 ms. We are benchmarking an expensive set of queries, and you\u2019ve probably noticed the sawtooth pattern in the plot and a high standard deviation relative to the latency. This is a symptom of bloat accumulating on our table. Query latency grows until the vacuum process clears dead tuples, and then grows once again. This also has an inverse impact on transactions per second (TPS). Ideally we can reduce and provide some stability to latency."),(0,o.kt)("h2",{id:"balancing-vacuum-delay-for-optimal-system-performance"},"Balancing Vacuum Delay for Optimal System Performance"),(0,o.kt)("p",null,"Vacuuming is indispensable. However, it is not free and if left unchecked, it can burden your system. The balance lies in ",(0,o.kt)("inlineCode",{parentName:"p"},"autovacuum_vacuum_cost_delay")," and ",(0,o.kt)("inlineCode",{parentName:"p"},"autovacuum_vacuum_cost_limit"),". ",(0,o.kt)("inlineCode",{parentName:"p"},"autovacuum_vacuum_cost_delay")," is the amount of time that the autovacuum process will halt processing when the ",(0,o.kt)("inlineCode",{parentName:"p"},"autovacuum_vacuum_cost_limit")," is reached. Imagine this series of events - a table reaches 10% bloat, meaning 10% of the tuples are dead. When the 10% threshold is reached, the autovacuum worker begins to work and starts accruing cost. When that cost reaches ",(0,o.kt)("inlineCode",{parentName:"p"},"autovacuum_vacuum_cost_limit"),", it will pause for the duration specified by ",(0,o.kt)("inlineCode",{parentName:"p"},"autovacuum_vacuum_cost_delay"),", and then continue working until it is complete."),(0,o.kt)("p",null,"Modifying these can craft the perfect balance between seamless vacuuming and system efficiency. Let\u2019s increase the cost limit to the max, and reduce the delay by  half. This will let the autovacuum process run longer and pause for a shorter period of time when it does reach the cost limit, to ideally reduce bloat faster and reduce query latency."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER SYSTEM SET autovacuum_vacuum_cost_delay = '10ms';\nALTER SYSTEM SET autovacuum_vacuum_cost_limit = 10000;\nSELECT pg_reload_conf();\n")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"delay_cost_limit",src:a(89010).Z,title:"delay-cost-limit",width:"1000",height:"600"})),(0,o.kt)("p",null,"We have a slight reduction in average latency, but we can still see that the obviously grows in latency over time and decrease in TPS. It clears roughly every 60 seconds."),(0,o.kt)("h2",{id:"fine-tuning-auto-vacuum-scale-factors"},"Fine-Tuning Auto Vacuum Scale Factors"),(0,o.kt)("p",null,"In the previous example, we manually vacuumed our table. But postgres gives us an automated way to configure the vacuum process. One of the most critical parameters is the ",(0,o.kt)("inlineCode",{parentName:"p"},"autovacuum_vacuum_scale_factor"),'; it denotes the portion of the table size that, when surpassed by "dead" rows, prompts a vacuum action. For tables that see frequent data changes, it might be beneficial to lessen this value.'),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER SYSTEM SET autovacuum_vacuum_scale_factor = 0.1;\nSELECT pg_reload_conf();\n")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"scale-factor",src:a(79888).Z,title:"scale-factor",width:"1000",height:"600"})),(0,o.kt)("p",null,"Reducing the scale factor had minimal impact on our result, so allowing the autovacuum to trigger sooner did not help. We can see that the period of the sawtooth pattern is still about 60 seconds, which means there we are probably limited by ",(0,o.kt)("inlineCode",{parentName:"p"},"autovacuum_naptime"),", which we'll talk about next."),(0,o.kt)("h2",{id:"a-quick-siesta-for-your-system"},"A Quick Siesta for Your System"),(0,o.kt)("p",null,"The autovacuum_naptime parameter in Postgres specifies the minimum delay between autovacuum runs on any given database. The default (which we set earlier) is ",(0,o.kt)("inlineCode",{parentName:"p"},"1min"),". Generally, depending on just how high-churn your workloads are, it might be necessary to decrease this value, whereas a longer interval could be suited for environments that are not churning at such a high rate. But our table has a crazy amount of churn."),(0,o.kt)("p",null,"We want to reduce the height of the latency peaks. One way to do this is to make the vacuum more aggressive and tell it to run sooner. We tried to influence that by setting the ",(0,o.kt)("inlineCode",{parentName:"p"},"autovacuum_vacuum_scale_factor"),", but we can also lower the ",(0,o.kt)("inlineCode",{parentName:"p"},"autovacuum_naptime")," value, which will also allow it to run sooner. Let\u2019s cut it in half."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER SYSTEM SET autovacuum_naptime = '30s';\nSELECT pg_reload_conf();\n")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"naptime",src:a(83167).Z,title:"naptime",width:"1000",height:"600"})),(0,o.kt)("p",null,"Allowing the autovacuumer to run more frequently reduced our average latency and increase TPS. However, we\u2019re still seeing a noticeable sawtooth pattern and high standard deviation of latency. Let\u2019s completely disable the cost limitations to the vacuum process, let it have as much compute as it needs."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER SYSTEM SET autovacuum_vacuum_cost_delay = '0';\nSELECT pg_reload_conf();\n")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"disable-cost",src:a(95973).Z,title:"disable-cost",width:"1000",height:"600"})),(0,o.kt)("p",null,"Finally, reduce naptime to 10s"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-sql"},"ALTER SYSTEM SET autovacuum_naptime = '10s';\nSELECT pg_reload_conf();\n")),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"naptime-final",src:a(73946).Z,title:"naptime-final",width:"1000",height:"600"})),(0,o.kt)("p",null,"Overall, we\u2019ve iterated on autovacuum settings and reduced the average latency from 3.4ms to 2.8ms and stddev from 0.8ms to 0.7ms, which helped increase TPS from 4.3k to about 5.3k."),(0,o.kt)("p",null,"Configuring the autovacuum settings can be a lot of fun and the appreciated values are wildly dependent on the workload. We covered the absurdly high churn use case on a single-table today, which is very similar to what we see when running applications using PGMQ. Vacuum is complicated and can be ",(0,o.kt)("a",{parentName:"p",href:"https://www.enterprisedb.com/blog/postgresql-vacuum-and-analyze-best-practice-tips"},"tuned differently")," when considering multiple tables with different workloads. Other OLTP use cases will call for different settings, and OLAP workloads may be less influenced by the vacuum settings . Follow us, and sign up for ",(0,o.kt)("a",{parentName:"p",href:"https://cloud.tembo.io"},"Tembo Cloud")," because we will surely be writing about these other topics soon."),(0,o.kt)("h2",{id:"more-on-this-topic"},"More on this topic"),(0,o.kt)("p",null,"Watch the video on ",(0,o.kt)("a",{parentName:"p",href:"https://www.youtube.com/watch?v=D832gi8Qrv4"},"Optimizing autovacuum: PostgreSQL\u2019s vacuum cleaner by Samay Sharma"),"."))}d.isMDXComponent=!0},73393:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/default-02ce369e1e17c9777de6749b0926159f.png"},89010:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/delay_limit-cd8db2fe56a5809a912c8d92bcbab133.png"},95973:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/disable_cost-d82a984a4c4bff36e6bd4bce3aad305b.png"},83167:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/naptime-f26979e9689635484e7e55d154a70968.png"},73946:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/naptime_final-25b01a2089dac176cf59357ee07ae222.png"},79888:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/scale_factor-3f330c83cc61eb06bc3c92af8348f85d.png"}}]);