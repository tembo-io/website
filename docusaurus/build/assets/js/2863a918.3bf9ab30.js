"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[6288],{3905:(e,t,n)=>{n.d(t,{Zo:()=>m,kt:()=>d});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),p=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},m=function(e){var t=p(e.components);return a.createElement(l.Provider,{value:t},e.children)},_="mdxType",y={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),_=p(n),h=r,d=_["".concat(l,".").concat(h)]||_[h]||y[h]||o;return n?a.createElement(d,s(s({ref:t},m),{},{components:n})):a.createElement(d,s({ref:t},m))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,s=new Array(o);s[0]=h;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[_]="string"==typeof e?e:r,s[1]=i;for(var p=2;p<o;p++)s[p]=n[p];return a.createElement.apply(null,s)}return a.createElement.apply(null,n)}h.displayName="MDXCreateElement"},75462:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>y,frontMatter:()=>o,metadata:()=>i,toc:()=>p});var a=n(87462),r=(n(67294),n(3905));const o={slug:"table-version-history",title:"Version History and Lifecycle Policies for Postgres Tables",authors:["steven"],tags:["postgres","extensions","temporal_tables","pg_partman","trunk"],image:"./images/back-in-time.jpeg"},s=void 0,i={permalink:"/blog/table-version-history",editUrl:"https://github.com/tembo-io/website/blob/main/blog/2023-09-29-table-version-history/index.md",source:"@site/blog/2023-09-29-table-version-history/index.md",title:"Version History and Lifecycle Policies for Postgres Tables",description:"back-in-time",date:"2023-09-29T00:00:00.000Z",formattedDate:"September 29, 2023",tags:[{label:"postgres",permalink:"/blog/tags/postgres"},{label:"extensions",permalink:"/blog/tags/extensions"},{label:"temporal_tables",permalink:"/blog/tags/temporal-tables"},{label:"pg_partman",permalink:"/blog/tags/pg-partman"},{label:"trunk",permalink:"/blog/tags/trunk"}],readingTime:17.85,hasTruncateMarker:!1,authors:[{name:"Steven Miller",title:"Founding Engineer",url:"https://github.com/sjmiller609",email:"noreply@tembo.io",imageURL:"https://github.com/sjmiller609.png",key:"steven"}],frontMatter:{slug:"table-version-history",title:"Version History and Lifecycle Policies for Postgres Tables",authors:["steven"],tags:["postgres","extensions","temporal_tables","pg_partman","trunk"],image:"./images/back-in-time.jpeg"},prevItem:{title:"Unlocking value from your Clerk User Management platform with Postgres",permalink:"/blog/clerk-fdw"},nextItem:{title:"Anatomy of a Postgres extension written in Rust: pgmq",permalink:"/blog/postgres-extension-in-rust-pgmq"}},l={image:n(81020).Z,authorsImageUrls:[void 0]},p=[{value:"Data model",id:"data-model",level:2},{value:"Getting set up",id:"getting-set-up",level:2},{value:"Basic demo of saving old versions",id:"basic-demo-of-saving-old-versions",level:2},{value:"Looking up past versions",id:"looking-up-past-versions",level:2},{value:"Partitioning",id:"partitioning",level:2},{value:"Performance",id:"performance",level:2},{value:"Writes",id:"writes",level:3},{value:"Reads",id:"reads",level:3},{value:"Expiring old versions",id:"expiring-old-versions",level:2},{value:"Thanks!",id:"thanks",level:2}],m={toc:p},_="wrapper";function y(e){let{components:t,...o}=e;return(0,r.kt)(_,(0,a.Z)({},m,o,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"back-in-time",src:n(81020).Z,width:"788",height:"453"})),(0,r.kt)("p",null,"A nice feature of AWS S3 is version history and lifecycle policies. When objects are updated or deleted, the old object version remains in the bucket, but it\u2019s hidden. Old versions are deleted eventually by the lifecycle policy."),(0,r.kt)("p",null,"I would like something like that for my Postgres table data. ",(0,r.kt)("strong",{parentName:"p"},"We can use the temporal_tables extension for version history, and combine it with pg_partman to partition by time, automatically expiring old versions.")),(0,r.kt)("h2",{id:"data-model"},"Data model"),(0,r.kt)("p",null,"Let's say we have a table ",(0,r.kt)("strong",{parentName:"p"},"employees"),", and it looks like this:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"       name       |  salary\n------------------+----------\n Bernard Marx     | 10000.00\n Lenina Crowne    |  7000.00\n Helmholtz Watson | 18500.00\n")),(0,r.kt)("p",null,"We will add one more column to this table, ",(0,r.kt)("inlineCode",{parentName:"p"},"sys_period"),', which is a time range. This time range represents "since when" is this row the current version. This range is unbounded on the right side, because all the rows in the ',(0,r.kt)("strong",{parentName:"p"},"employees")," table are the present version."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'       name       |  salary  |             sys_period\n------------------+----------+------------------------------------\n Helmholtz Watson | 18500.00 | ["2023-09-28 13:30:19.24318+00",)\n Bernard Marx     | 11600.00 | ["2023-09-28 13:33:58.735932+00",)\n Lenina Crowne    | 11601.00 | ["2023-09-28 13:33:58.738827+00",)\n')),(0,r.kt)("p",null,"We will make a new table ",(0,r.kt)("strong",{parentName:"p"},"employees_history")," to store previous versions. This will have the same columns as the ",(0,r.kt)("strong",{parentName:"p"},"employees")," table, but all the rows in ",(0,r.kt)("inlineCode",{parentName:"p"},"sys_period")," are bounded on the the right and the left sides. These ranges represent when this row was the current version. We will configure ",(0,r.kt)("strong",{parentName:"p"},"temporal_tables")," to automatically create these rows when anything changes in the ",(0,r.kt)("strong",{parentName:"p"},"employees")," table."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'     name      |  salary  |                            sys_period\n---------------+----------+-------------------------------------------------------------------\n Bernard Marx  | 10000.00 | ["2023-09-28 13:30:19.18544+00","2023-09-28 13:33:58.683279+00")\n Bernard Marx  | 11200.00 | ["2023-09-28 13:33:58.683279+00","2023-09-28 13:33:58.731332+00")\n Bernard Marx  | 11400.00 | ["2023-09-28 13:33:58.731332+00","2023-09-28 13:33:58.735932+00")\n Lenina Crowne |  7000.00 | ["2023-09-28 13:30:19.239152+00","2023-09-28 13:33:58.738827+00")\n')),(0,r.kt)("p",null,"To automatically delete old versions, we'll add one more column to the ",(0,r.kt)("strong",{parentName:"p"},"employees_table"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"created_at"),". We will use this information to expire old versions after they are older than our retenion configuration, with the help of ",(0,r.kt)("strong",{parentName:"p"},"pg_partman"),"."),(0,r.kt)("h2",{id:"getting-set-up"},"Getting set up"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://tembo.io/docs/tembo-cloud/try-extensions-locally"},"This guide")," covers how to quickly try out Postgres extensions locally. I've followed that guide to set up my environment with ",(0,r.kt)("strong",{parentName:"p"},"temporal_tables")," and ",(0,r.kt)("strong",{parentName:"p"},"pg_partman"),"."),(0,r.kt)("p",null,"I have a Dockefile, two SQL scripts, and a file with Postgres configurations."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},".\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 0_startup.sql\n\u251c\u2500\u2500 1_create_versioned_table.sql\n\u2514\u2500\u2500 custom.conf\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Dockerfile:")," We use ",(0,r.kt)("a",{parentName:"p",href:"https://pgt.dev"},"Trunk")," to install pg_partman and temporal_tables. Then, we copy the three other files into the image."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-Dockerfile"},"FROM quay.io/tembo/tembo-local:latest\n\nRUN trunk install pg_partman\nRUN trunk install temporal_tables\n\nCOPY 0_startup.sql $PGDATA/startup-scripts\n\nCOPY 1_create_versioned_table.sql $PGDATA/startup-scripts\n\nCOPY custom.conf $PGDATA/extra-configs\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"0_startup.sql:")," Enables temporal_tables and pg_partman when Postgres starts."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE EXTENSION IF NOT EXISTS temporal_tables;\nCREATE EXTENSION IF NOT EXISTS pg_partman;\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"1_create_versioned_table.sql:")," Creates a sample table, then enables version history on it."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"-- Sample: an existing table we want to enable versioning on\nCREATE TABLE employees\n(\n  name text NOT NULL PRIMARY KEY,\n  department text,\n  salary numeric(20, 2)\n);\n\n/*\nAdding version history to the table,\nfirst we need to add a time range to the existing table.\nThis represents \"since when\" has this row been current.\n*/\nALTER TABLE employees ADD COLUMN sys_period tstzrange NOT NULL;\n\n/*\nCreating a time-partitioned version table\neach row has the range the data was valid for,\nand also the time this version was created.\n*/\nCREATE TABLE employees_history (\n    LIKE employees INCLUDING DEFAULTS EXCLUDING INDEXES EXCLUDING CONSTRAINTS,\n    created_at timestamptz NOT NULL DEFAULT now())\n    PARTITION BY RANGE (created_at);\n\n-- Allow efficient querying of partition key and name\nCREATE INDEX ON employees_history (created_at);\n\n/*\nEnable automatic partitioning with pg_partman, partitioning every 1 minute.\n\nIt's more realistic to partition daily or greater.\n*/\nSELECT create_parent('public.employees_history', 'created_at', 'native', '1 minute');\n\n-- This connects employees table to employees_history\nCREATE TRIGGER versioning_trigger\n    BEFORE INSERT OR UPDATE OR DELETE ON employees\n    FOR EACH ROW EXECUTE PROCEDURE versioning('sys_period',\n                                              'employees_history',\n                                              true);\n\n/*\nConfigure retention policy for employee history to keep old versions for 10 minutes.\n\nIt's more realistic to configure retention for 1 year.\n*/\nUPDATE part_config\n    SET retention = '10 minutes',\n        retention_keep_table = false,\n        retention_keep_index = false,\n        infinite_time_partitions = true\n    WHERE parent_table = 'public.employees_history';\n\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"custom.conf:")," our additions to the Postgres configuration."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"# Enable pg_partman background worker\nshared_preload_libraries = 'pg_partman_bgw'\n\n# How many seconds between pg_partman background worker runs\n# It's more realistic to run every 3600 seconds, or longer\npg_partman_bgw.interval = 10\n\n# Which database pg_partman should target\npg_partman_bgw.dbname = 'postgres'\n\n# It's best practice to use limited permissions for the background worker\n# pg_partman_bgw.role = 'limitedrole'\n\n# This was helpful when I was working on getting the settings working\n# log_min_messages = 'DEBUG1'\n")),(0,r.kt)("p",null,"With those four files in place, we can run Postgres like this:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"docker build -t example-local-image .\ndocker run -it -d --name local-tembo -p 5432:5432 --rm example-local-image\n")),(0,r.kt)("p",null,"In a separate shell, I connect into the Postgres container."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"psql postgres://postgres:postgres@localhost:5432\n")),(0,r.kt)("h2",{id:"basic-demo-of-saving-old-versions"},"Basic demo of saving old versions"),(0,r.kt)("p",null,"After we are set up, we have version history and retention policy configured on the ",(0,r.kt)("strong",{parentName:"p"},"employees")," table, but both the ",(0,r.kt)("strong",{parentName:"p"},"employees")," table and the ",(0,r.kt)("strong",{parentName:"p"},"employees_history")," table are empty."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM employees;\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"}," name | department | salary | sys_period\n------+------------+--------+------------\n(0 rows)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM employees_history;\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"}," name | department | salary | sys_period | created_at\n------+------------+--------+------------+------------\n(0 rows)\n")),(0,r.kt)("p",null,"Adding data:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"INSERT INTO employees (name, department, salary)\nVALUES ('Bernard Marx', 'Hatchery and Conditioning Centre', 10000);\n\nINSERT INTO employees (name, department, salary)\nVALUES ('Lenina Crowne', 'Hatchery and Conditioning Centre', 7000);\n\nINSERT INTO employees (name, department, salary)\nVALUES ('Helmholtz Watson', 'College of Emotional Engineering', 18500);\n")),(0,r.kt)("p",null,"Now, the ",(0,r.kt)("strong",{parentName:"p"},"employees")," has some data, and ",(0,r.kt)("strong",{parentName:"p"},"employees_history")," is still empty."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT name, salary, sys_period FROM employees;\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'       name       |   salary  |             sys_period\n------------------+-----------+------------------------------------\n Bernard Marx     |  10000.00 | ["2023-09-28 20:23:14.840624+00",)\n Lenina Crowne    |   7000.00 | ["2023-09-28 20:23:14.911528+00",)\n Helmholtz Watson |  18500.00 | ["2023-09-28 20:23:14.913555+00",)\n(3 rows)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT * FROM employees_history;\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"}," name | department | salary | sys_period | created_at\n------+------------+--------+------------+------------\n(0 rows)\n")),(0,r.kt)("p",null,"Modifying data:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"UPDATE employees SET salary = 11200 WHERE name = 'Bernard Marx';\nUPDATE employees SET salary = 11400 WHERE name = 'Bernard Marx';\nUPDATE employees SET salary = 11600 WHERE name = 'Bernard Marx';\nUPDATE employees SET salary = 11601 WHERE name = 'Lenina Crowne';\n")),(0,r.kt)("p",null,"Now, the ",(0,r.kt)("strong",{parentName:"p"},"employees_history")," table has past versions."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT name, salary, sys_period FROM employees;\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'       name       |  salary  |             sys_period\n------------------+----------+------------------------------------\n Helmholtz Watson | 18500.00 | ["2023-09-28 20:23:14.913555+00",)\n Bernard Marx     | 11600.00 | ["2023-09-28 20:23:50.731597+00",)\n Lenina Crowne    | 11601.00 | ["2023-09-28 20:23:50.734214+00",)\n(3 rows)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT name, salary, sys_period FROM employees_history;\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'     name      |  salary  |                            sys_period\n---------------+----------+-------------------------------------------------------------------\n Bernard Marx  | 10000.00 | ["2023-09-28 20:23:14.840624+00","2023-09-28 20:23:50.684293+00")\n Bernard Marx  | 11200.00 | ["2023-09-28 20:23:50.684293+00","2023-09-28 20:23:50.727283+00")\n Bernard Marx  | 11400.00 | ["2023-09-28 20:23:50.727283+00","2023-09-28 20:23:50.731597+00")\n Lenina Crowne |  7000.00 | ["2023-09-28 20:23:14.911528+00","2023-09-28 20:23:50.734214+00")\n(4 rows)\n')),(0,r.kt)("h2",{id:"looking-up-past-versions"},"Looking up past versions"),(0,r.kt)("p",null,"Let's say we want to look up Bernard's salary at a previous date. We can check the ",(0,r.kt)("strong",{parentName:"p"},"employees_history")," table to find the row where the time range matches our provided timestamp. However, this wouldn't find the correct salary if we provide a timestamp that is after the most recent update to Bernard's salary, since that row is in the ",(0,r.kt)("strong",{parentName:"p"},"employees")," table."),(0,r.kt)("p",null,"We can first create a ",(0,r.kt)("a",{parentName:"p",href:"https://www.postgresql.org/docs/current/tutorial-views.html"},"view")," for this purpose. We only need to do this once, then we can query this view like a table going forward."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"CREATE VIEW employee_history_view AS\n\nSELECT name, department, salary, sys_period\nFROM employees\n\nUNION ALL\n\nSELECT name, department, salary, sys_period\nFROM employees_history;\n")),(0,r.kt)("p",null,"Then, we can use this query to find Bernard's salary at any given date."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT salary\nFROM employee_history_view\nWHERE name = 'Bernard Marx'\nAND sys_period @> TIMESTAMP WITH TIME ZONE '2023-09-28 20:23:30+00'\nLIMIT 1;\n")),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"@>")," Is a ",(0,r.kt)("em",{parentName:"p"},"containment operator")," and you might recognize it if you have used ",(0,r.kt)("a",{parentName:"p",href:"https://tembo.io/docs/postgres_guides/postgres-basics/jsonb"},"JSONB"),"."),(0,r.kt)("p",null,"Comparing to the ",(0,r.kt)("strong",{parentName:"p"},"employees_history")," table shown above, it is returning the correct value."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"  salary\n----------\n 10000.00\n(1 row)\n")),(0,r.kt)("p",null,"It also works to look up the current salary:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT salary\nFROM employee_history_view\nWHERE name = 'Bernard Marx'\nAND sys_period @> now()::TIMESTAMP WITH TIME ZONE\nLIMIT 1;\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"  salary\n----------\n 11600.00\n(1 row)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT salary FROM employees WHERE name = 'Bernard Marx';\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"  salary\n----------\n 11600.00\n(1 row)\n")),(0,r.kt)("p",null,"If I try to query a salary from the future, it will return the current salary. If I try to query a salary from before Bernard is known in the ",(0,r.kt)("strong",{parentName:"p"},"employees_history")," table, then I get an empty result."),(0,r.kt)("h2",{id:"partitioning"},"Partitioning"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"What is partitioning?")," ",(0,r.kt)("a",{parentName:"p",href:"https://www.postgresql.org/docs/current/ddl-partitioning.html"},"Postgres documentation")," has detailed information on partitioning but just to summarize, partitioning is about splitting what is logically one large table into smaller tables. Typically, this is done for query performance. In our case, ",(0,r.kt)("strong",{parentName:"p"},"we are partitioning to expire old versions.")),(0,r.kt)("p",null,"Partitioning tables is something I\u2019m familiar with from Tembo\u2019s work in ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/tembo-io/pgmq"},"PGMQ"),", which is a queueing extension for Postgres."),(0,r.kt)("h2",{id:"performance"},"Performance"),(0,r.kt)("h3",{id:"writes"},"Writes"),(0,r.kt)("p",null,"We should expect write performance to be slower, since we are writing to two tables for every update."),(0,r.kt)("p",null,"I created a new table that does not have versioning enabled to compare write performance."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"-- Create a table like employees\nCREATE TABLE employees_write_test\nAS TABLE employees\nWITH NO DATA;\n\n-- ...and insert one row\nINSERT INTO employees_write_test (name, department, salary, sys_period)\nVALUES ('Bernard Marx', 'Hatchery and Conditioning Centre', 11600.00, tstzrange(now(), null));\n")),(0,r.kt)("p",null,"Then, I used ",(0,r.kt)("inlineCode",{parentName:"p"},"EXPLAIN ANALYZE")," to compare the write performance. I ran the query a few times for each."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Without versioning:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"EXPLAIN ANALYZE\nUPDATE employees_write_test\nSET salary = 11608 WHERE name = 'Bernard Marx';\n")),(0,r.kt)("p",null,"Three samples:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"}," Planning Time: 1.654 ms\n Execution Time: 1.540 ms\n\n Planning Time: 0.760 ms\n Execution Time: 0.707 ms\n\n Planning Time: 1.707 ms\n Execution Time: 2.079 ms\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"With versioning:")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"EXPLAIN ANALYZE\nUPDATE employees\nSET salary = 11610 WHERE name = 'Bernard Marx';\n")),(0,r.kt)("p",null,"Three samples:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"}," Planning Time: 2.423 ms\n Trigger versioning_trigger: time=2.430 calls=1\n Execution Time: 4.783 ms\n\n Planning Time: 2.311 ms\n Trigger versioning_trigger: time=1.091 calls=1\n Execution Time: 2.979 ms\n\n Planning Time: 2.825 ms\n Trigger versioning_trigger: time=1.711 calls=1\n Execution Time: 5.686 ms\n")),(0,r.kt)("p",null,"It's more than twice as slow on a single update. That's because we have to write to two rows instead of one, there is more data to write (the time ranges), and because there is some additional processing, for instance determining which range to put on each row. In the next section, I also compare how much time it takes to write 100,000 rows in each of these tables."),(0,r.kt)("h3",{id:"reads"},"Reads"),(0,r.kt)("p",null,"We created a view which is a union between ",(0,r.kt)("strong",{parentName:"p"},"employees")," and ",(0,r.kt)("strong",{parentName:"p"},"employees_history"),", then we query the view to find an employee's salary at a given time."),(0,r.kt)("p",null,"To generate some data, let's make a procedure to update a salary 100,000 times in a row. The below example uses ",(0,r.kt)("a",{parentName:"p",href:"https://www.postgresql.org/docs/current/plpgsql.html"},"PL/pgSQL"),". By default, PL/pgSQL functions run as a single transaction, so it would only result in a single update to the ",(0,r.kt)("strong",{parentName:"p"},"employees_history")," table. For this reason, I am using a procedure with ",(0,r.kt)("inlineCode",{parentName:"p"},"COMMIT")," so that each increment will be a separate transaction, this way we also get 100,000 updates to the ",(0,r.kt)("strong",{parentName:"p"},"employees_history")," table. I had to explain that nuance to chatGPT in order for this procedure to be produced properly."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"-- Table name and employee name as inputs\nCREATE OR REPLACE PROCEDURE increment_salary(p_name text, p_table_name text)\nLANGUAGE plpgsql AS $$\nDECLARE\n    v_salary numeric(20,2);\n    i integer;\n    v_sql text;\nBEGIN\n    -- Dynamically construct the SQL to get the current salary\n    v_sql := format('SELECT salary FROM %I WHERE name = $1', p_table_name);\n    EXECUTE v_sql INTO v_salary USING p_name;\n\n    -- Loop 100 thousand times\n    FOR i IN 1..100000\n    LOOP\n        -- Increment the salary\n        v_salary := v_salary + 1;\n\n        -- Dynamically construct the SQL to update the salary\n        v_sql := format('UPDATE %I SET salary = $2 WHERE name = $1', p_table_name);\n        EXECUTE v_sql USING p_name, v_salary;\n\n        COMMIT;  -- Commit the transaction, triggering the versioning procedure\n    END LOOP;\nEND\n$$;\n")),(0,r.kt)("p",null,"Run the procedure:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"CALL increment_salary('Bernard Marx', 'employees');\n")),(0,r.kt)("p",null,"This took 55 seconds to run on my laptop. I also tried it on the table without versioning enabled, at in this case it took 38 seconds. I ran it a couple more times on the table with versioning enabled, so that the versions would be distributed across multiple partitions. Now we have an ",(0,r.kt)("strong",{parentName:"p"},"employees_history")," table that's populated with many rows for Bernard."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"SELECT count(*) FROM employees_history WHERE name = 'Bernard Marx';\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"}," count\n--------\n 300000\n(1 row)\n")),(0,r.kt)("p",null,"Let's run the same type of query command we ran before, with ",(0,r.kt)("inlineCode",{parentName:"p"},"EXPLAIN ANALYZE"),". I picked a timestamp that will not be found to ensure it's as slow as possible."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"EXPLAIN ANALYZE\nSELECT salary\nFROM employee_history_view\nWHERE name = 'Bernard Marx'\nAND sys_period @> TIMESTAMP WITH TIME ZONE '2023-09-28 15:28:25+00'\nLIMIT 1;\n")),(0,r.kt)("p",null,"Simplified query plan output:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Limit\n  ->  Append\n        ->  Bitmap Heap Scan on employees\n              Recheck Cond: (name = 'Bernard Marx'::text)\n              Filter: (sys_period @> '...')\n              Rows Removed by Filter: 1\n              Heap Blocks: exact=1\n              ->  Bitmap Index Scan on employees_pkey\n                    Index Cond: (name = 'Bernard Marx'::text)\n\n        ... Empty partitions omitted ...\n\n        ->  Seq Scan on employees_history_p2023_09_29_0030\n              Filter: ((sys_period @> '...') AND (name = 'Bernard Marx'::text))\n              Rows Removed by Filter: 31\n\n        ->  Seq Scan on employees_history_p2023_09_29_0031\n              Filter: ((sys_period @> '...') AND (name = 'Bernard Marx'::text))\n              Rows Removed by Filter: 99969\n\n        ... Empty partitions omitted ...\n\n        ->  Seq Scan on employees_history_p2023_09_29_0035\n              Filter: ((sys_period @> '...') AND (name = 'Bernard Marx'::text))\n              Rows Removed by Filter: 97393\n\n        ->  Seq Scan on employees_history_p2023_09_29_0036\n              Filter: ((sys_period @> '...') AND (name = 'Bernard Marx'::text))\n              Rows Removed by Filter: 102607\n\n        ... Empty partitions omitted ...\n\nPlanning Time: 12.427 ms\nExecution Time: 262.706 ms\n(47 rows)\n")),(0,r.kt)("p",null,"This query took 263 milliseconds. We notice this query needs to scan all partitions, because we are partitioning by ",(0,r.kt)("inlineCode",{parentName:"p"},"created_at"),", and querying ",(0,r.kt)("inlineCode",{parentName:"p"},"sys_period"),". We can improve the speed with indexes."),(0,r.kt)("p",null,"If this was a real workload, I doubt that employees' salaries are being updated so frequently, or at least that's been the case in my personal experience. However, if it's a big company, then there could be a lot of employees. In that case, it would be best to add an index on the name (or more realistically, employee ID) in the ",(0,r.kt)("strong",{parentName:"p"},"employees_history")," table. Then, withing each partition it will find only rows for the employee being queryed using the index, then it would scan the remaining rows, probably typically zero, one, or two rows, to find the correct salary."),(0,r.kt)("h2",{id:"expiring-old-versions"},"Expiring old versions"),(0,r.kt)("p",null,"Earlier in this blog, we configured ",(0,r.kt)("strong",{parentName:"p"},"pg_partman")," to partition in 1 minute increments, to expire partitions that are older than 15 minutes, and to check every 30 seconds. Every 30 seconds, any partition that is older that 15 minutes is deleted by the ",(0,r.kt)("strong",{parentName:"p"},"pg_partman")," background worker."),(0,r.kt)("p",null,"With this query, I can check how many rows and the total data size in each partition."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-sql"},"-- This query was produced by ChatGPT 4 with the prompt:\n-- \"How can I check the number of rows in each partition of employees_history?\"\nSELECT\n    child.relname AS partition_name,\n    pg_total_relation_size(child.oid) AS total_size,\n    pg_relation_size(child.oid) AS data_size,\n    pg_stat_user_tables.n_live_tup AS row_count\nFROM\n    pg_inherits\nJOIN\n    pg_class parent ON pg_inherits.inhparent = parent.oid\nJOIN\n    pg_class child ON pg_inherits.inhrelid = child.oid\nLEFT JOIN\n    pg_stat_user_tables ON child.oid = pg_stat_user_tables.relid\nWHERE\n    parent.relname='employees_history'\nORDER BY\n    partition_name;\n")),(0,r.kt)("p",null,"In order to check that old versions are being dropped, I ran the procedure to create a lot of salaray increments several times in a row."),(0,r.kt)("p",null,"Then, running the above query, I find an output like this:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"           partition_name           | total_size | data_size | row_count\n------------------------------------+------------+-----------+-----------\n employees_history_default          |      16384 |         0 |         0\n employees_history_p2023_09_28_2204 |      16384 |         0 |         0\n employees_history_p2023_09_28_2205 |      16384 |         0 |         0\n employees_history_p2023_09_28_2206 |      16384 |         0 |         0\n employees_history_p2023_09_28_2207 |      16384 |         0 |         0\n employees_history_p2023_09_28_2208 |      16384 |         0 |         0\n employees_history_p2023_09_28_2209 |      16384 |         0 |         0\n employees_history_p2023_09_28_2210 |      32768 |      8192 |         4\n employees_history_p2023_09_28_2211 |    9584640 |   7995392 |     68267\n employees_history_p2023_09_28_2212 |    4489216 |   3719168 |     31733\n employees_history_p2023_09_28_2213 |   13180928 |  11018240 |     94144\n employees_history_p2023_09_28_2214 |     868352 |    688128 |      5856\n employees_history_p2023_09_28_2215 |      16384 |         0 |         0\n employees_history_p2023_09_28_2216 |      16384 |         0 |         0\n employees_history_p2023_09_28_2217 |      16384 |         0 |         0\n employees_history_p2023_09_28_2218 |      16384 |         0 |         0\n(16 rows)\n")),(0,r.kt)("p",null,"In this output, we can see that we have 1 partition for every minute, and a total of 15 partitions. I have old versions expiring after 10 minutes. I thought it's interesting to note that ",(0,r.kt)("strong",{parentName:"p"},"pg_partman")," is preemptively creating partitions for the future, in this case 5 minutes into the future."),(0,r.kt)("p",null,"If you refer to the original set up steps, I have configured ",(0,r.kt)("inlineCode",{parentName:"p"},"infinite_time_partitions = true"),", and this means we will generate partitions even when we are not generating any data for them. I think this is the proper configuration since we also have a retention policy that will drop the old partitions. The concern of making infinite partitions as time passes, even if no data is being generated, is not applicable because old tables are being dropped."),(0,r.kt)("p",null,"To confirm data was being deleted, I sampled the above query over time, and we can see the large body of inserts moving up into the oldest available partitions, then falling outside of the retention policy and being deleted."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"\n           partition_name           | total_size | data_size | row_count\n------------------------------------+------------+-----------+-----------\n employees_history_default          |      16384 |         0 |         0\n employees_history_p2023_09_28_2207 |      16384 |         0 |         0\n employees_history_p2023_09_28_2208 |      16384 |         0 |         0\n employees_history_p2023_09_28_2209 |      16384 |         0 |         0\n employees_history_p2023_09_28_2210 |      32768 |      8192 |         4\n employees_history_p2023_09_28_2211 |    9584640 |   7995392 |     68267\n employees_history_p2023_09_28_2212 |    4489216 |   3719168 |     31733\n employees_history_p2023_09_28_2213 |   13189120 |  11018240 |     94144\n employees_history_p2023_09_28_2214 |     876544 |    688128 |      5856\n employees_history_p2023_09_28_2215 |      16384 |         0 |         0\n employees_history_p2023_09_28_2216 |      16384 |         0 |         0\n employees_history_p2023_09_28_2217 |      16384 |         0 |         0\n employees_history_p2023_09_28_2218 |      16384 |         0 |         0\n employees_history_p2023_09_28_2219 |      16384 |         0 |         0\n employees_history_p2023_09_28_2220 |      16384 |         0 |         0\n employees_history_p2023_09_28_2221 |      16384 |         0 |         0\n(16 rows)\n\n\n           partition_name           | total_size | data_size | row_count\n------------------------------------+------------+-----------+-----------\n employees_history_default          |      16384 |         0 |         0\n employees_history_p2023_09_28_2211 |    9584640 |   7995392 |     68267\n employees_history_p2023_09_28_2212 |    4489216 |   3719168 |     31733\n employees_history_p2023_09_28_2213 |   13189120 |  11018240 |     94144\n employees_history_p2023_09_28_2214 |     876544 |    688128 |      5856\n employees_history_p2023_09_28_2215 |      16384 |         0 |         0\n employees_history_p2023_09_28_2216 |      16384 |         0 |         0\n employees_history_p2023_09_28_2217 |      16384 |         0 |         0\n employees_history_p2023_09_28_2218 |      16384 |         0 |         0\n employees_history_p2023_09_28_2219 |      16384 |         0 |         0\n employees_history_p2023_09_28_2220 |      16384 |         0 |         0\n employees_history_p2023_09_28_2221 |      16384 |         0 |         0\n employees_history_p2023_09_28_2222 |      16384 |         0 |         0\n employees_history_p2023_09_28_2223 |      16384 |         0 |         0\n employees_history_p2023_09_28_2224 |      16384 |         0 |         0\n employees_history_p2023_09_28_2225 |      16384 |         0 |         0\n(16 rows)\n\n\n           partition_name           | total_size | data_size | row_count\n------------------------------------+------------+-----------+-----------\n employees_history_default          |      16384 |         0 |         0\n employees_history_p2023_09_28_2212 |    4489216 |   3719168 |     31733\n employees_history_p2023_09_28_2213 |   13189120 |  11018240 |     94144\n employees_history_p2023_09_28_2214 |     876544 |    688128 |      5856\n employees_history_p2023_09_28_2215 |      16384 |         0 |         0\n employees_history_p2023_09_28_2216 |      16384 |         0 |         0\n employees_history_p2023_09_28_2217 |      16384 |         0 |         0\n employees_history_p2023_09_28_2218 |      16384 |         0 |         0\n employees_history_p2023_09_28_2219 |      16384 |         0 |         0\n employees_history_p2023_09_28_2220 |      16384 |         0 |         0\n employees_history_p2023_09_28_2221 |      16384 |         0 |         0\n employees_history_p2023_09_28_2222 |      16384 |         0 |         0\n employees_history_p2023_09_28_2223 |      16384 |         0 |         0\n employees_history_p2023_09_28_2224 |      16384 |         0 |         0\n employees_history_p2023_09_28_2225 |      16384 |         0 |         0\n employees_history_p2023_09_28_2226 |      16384 |         0 |         0\n(16 rows)\n\npostgres=# select count(*) from employees_history;\n count\n--------\n 131733\n(1 row)\n\n           partition_name           | total_size | data_size | row_count\n------------------------------------+------------+-----------+-----------\n employees_history_default          |      16384 |         0 |         0\n employees_history_p2023_09_28_2214 |     876544 |    688128 |      5856\n employees_history_p2023_09_28_2215 |      16384 |         0 |         0\n employees_history_p2023_09_28_2216 |      16384 |         0 |         0\n employees_history_p2023_09_28_2217 |      16384 |         0 |         0\n employees_history_p2023_09_28_2218 |      16384 |         0 |         0\n employees_history_p2023_09_28_2219 |      16384 |         0 |         0\n employees_history_p2023_09_28_2220 |      16384 |         0 |         0\n employees_history_p2023_09_28_2221 |      16384 |         0 |         0\n employees_history_p2023_09_28_2222 |      16384 |         0 |         0\n employees_history_p2023_09_28_2223 |      16384 |         0 |         0\n employees_history_p2023_09_28_2224 |      16384 |         0 |         0\n employees_history_p2023_09_28_2225 |      16384 |         0 |         0\n employees_history_p2023_09_28_2226 |      16384 |         0 |         0\n employees_history_p2023_09_28_2227 |      16384 |         0 |         0\n employees_history_p2023_09_28_2228 |      16384 |         0 |         0\n(16 rows)\n\npostgres=# select count(*) from employees_history;\n count\n-------\n  5856\n(1 row)\n\n           partition_name           | total_size | data_size | row_count\n------------------------------------+------------+-----------+-----------\n employees_history_default          |      16384 |         0 |         0\n employees_history_p2023_09_28_2215 |      16384 |         0 |         0\n employees_history_p2023_09_28_2216 |      16384 |         0 |         0\n employees_history_p2023_09_28_2217 |      16384 |         0 |         0\n employees_history_p2023_09_28_2218 |      16384 |         0 |         0\n employees_history_p2023_09_28_2219 |      16384 |         0 |         0\n employees_history_p2023_09_28_2220 |      16384 |         0 |         0\n employees_history_p2023_09_28_2221 |      16384 |         0 |         0\n employees_history_p2023_09_28_2222 |      16384 |         0 |         0\n employees_history_p2023_09_28_2223 |      16384 |         0 |         0\n employees_history_p2023_09_28_2224 |      16384 |         0 |         0\n employees_history_p2023_09_28_2225 |      16384 |         0 |         0\n employees_history_p2023_09_28_2226 |      16384 |         0 |         0\n employees_history_p2023_09_28_2227 |      16384 |         0 |         0\n employees_history_p2023_09_28_2228 |      16384 |         0 |         0\n employees_history_p2023_09_28_2229 |      16384 |         0 |         0\n(16 rows)\n\npostgres=# select count(*) from employees_history;\n count\n-------\n     0\n(1 row)\n")),(0,r.kt)("h2",{id:"thanks"},"Thanks!"),(0,r.kt)("p",null,"If you got this far, thank you for reading this! I hope that you are inspired to try out extensions on your own and see what they can do. The next time you have some problem to solve with your data, consider that maybe it could just be handled by a Postgres extension."),(0,r.kt)("p",null,"If you want to try extensions without any local setup, you should try Tembo Cloud at ",(0,r.kt)("a",{parentName:"p",href:"https://cloud.tembo.io"},"cloud.tembo.io"),"."),(0,r.kt)("p",null,"Just use Postgres!"))}y.isMDXComponent=!0},81020:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/back-in-time-1adcd964a1d80bc51e3abee252d02e3c.jpeg"}}]);